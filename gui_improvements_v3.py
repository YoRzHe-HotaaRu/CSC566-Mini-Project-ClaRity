"""
COMPREHENSIVE GUI IMPROVEMENTS FOR VLM ANALYSIS MODE
"""

import sys
from pathlib import Path

project_root = Path(__file__).parent
sys.path.insert(0, str(project_root))

gui_file = project_root / "gui" / "main_window.py"
with open(gui_file, 'r', encoding='utf-8') as f:
    content = f.read()

# Track changes
changes = []

# Fix 1: Layer Legend visibility
old1 = '            legend_item.setVisible(False)  # Initially hidden'
new1 = '            legend_item.setVisible(True)  # Make visible by default'
if old1 in content:
    content = content.replace(old1, new1)
    changes.append("âœ… Layer Legend visible by default")

# Fix 1b: Ensure legend widget is visible
if 'self.legend_widget.setVisible(True)' not in content:
    old1b = '        legend_layout.addWidget(self.legend_widget)  # Add legend widget to main layout\n        layout.addWidget(self.legend_group)'
    new1b = '        legend_layout.addWidget(self.legend_widget)  # Add legend widget to main layout\n        self.legend_widget.setVisible(True)\n        layout.addWidget(self.legend_group)'
    content = content.replace(old1b, new1b)
    changes.append("âœ… Legend widget visibility ensured")

# Fix 2: VLM visualization
old2 = '                    result["labels"] = np.ones(self.image.shape[:2], dtype=np.uint8) * vlm_result.get("layer_number", 1)'
new2 = '''                    # Create smart VLM visualization
                    h, w = self.image.shape[:2]
                    layer_num = vlm_result.get("layer_number", 1)
                    
                    # Create visualization with detected layer
                    labels = np.ones((h, w), dtype=np.uint8) * layer_num
                    
                    # Add border to indicate image boundary
                    border_width = min(h, w) // 20
                    labels[:border_width, :] = 0
                    labels[-border_width:, :] = 0
                    labels[:, :border_width] = 0
                    labels[:, -border_width:] = 0
                    
                    # Add confidence-based overlay
                    confidence = vlm_result.get("confidence", 0.5)
                    if confidence < 0.7:
                        noise_mask = np.random.random((h, w)) > confidence
                        labels[noise_mask] = 0
                    
                    result["labels"] = labels'''

if old2 in content:
    content = content.replace(old2, new2)
    changes.append("âœ… VLM smart visualization with border and confidence overlay")

# Fix 3: Rich results display
old3 = '''        # Display results text
        classification = result.get("classification", {})
        features = result.get("features", {})
        
        text = "â•â•â• ANALYSIS RESULTS â•â•â•\\n\\n"
        text += f"Detected Layer: {classification.get('layer_name', 'N/A')}\\n"
        text += f"Confidence: {classification.get('confidence', 0):.1%}\\n"
        text += f"Material: {classification.get('material', 'N/A')}\\n"
        text += f"Method: {classification.get('method', 'N/A')}\\n\\n"
        
        if "glcm" in features:
            glcm = features["glcm"]
            text += "â”€â”€â”€ GLCM Features â”€â”€â”€\\n"
            text += f"Contrast:    {glcm.get('contrast', 0):.4f}\\n"
            text += f"Energy:      {glcm.get('energy', 0):.4f}\\n"
            text += f"Homogeneity: {glcm.get('homogeneity', 0):.4f}\\n"
            text += f"Correlation: {glcm.get('correlation', 0):.4f}\\n"
        
        self.results_text.setText(text)'''

new3 = '''        # Display results text
        classification = result.get("classification", {})
        features = result.get("features", {})
        
        text = "â•â•â• ANALYSIS RESULTS â•â•â•\\n\\n"
        
        # Layer identification
        layer_name = classification.get('layer_name', classification.get('full_name', 'N/A'))
        confidence = classification.get('confidence', 0)
        text += f"ğŸ” Detected Layer: {layer_name}\\n"
        text += f"ğŸ“Š Confidence: {confidence:.1%}\\n"
        
        # Material info
        material = classification.get('material', 'N/A')
        if material and material != 'N/A':
            text += f"ğŸ§± Material: {material}\\n"
        
        # Method used
        method = classification.get('method', 'N/A')
        if method == 'N/A':
            method = "VLM Analysis (GLM-4.6V)"
        text += f"âš™ï¸  Method: {method}\\n"
        
        # Layer number
        layer_num = classification.get('layer_number')
        if layer_num:
            text += f"ğŸ”¢ Layer Number: {layer_num}\\n"
        
        # VLM-specific fields
        texture = classification.get('texture_description')
        if texture and texture != 'N/A':
            text += f"\\nğŸ¨ Texture Description:\\n   {texture}\\n"
        
        reasoning = classification.get('reasoning')
        if reasoning and reasoning != 'N/A':
            text += f"\\nğŸ§  Analysis Reasoning:\\n   {reasoning}\\n"
        
        notes = classification.get('additional_notes')
        if notes and notes != 'N/A':
            text += f"\\nğŸ“ Additional Notes:\\n   {notes}\\n"
        
        # GLCM features (only for classical/hybrid modes)
        if "glcm" in features and self.mode in ["classical", "hybrid"]:
            text += "\\nâ”€â”€â”€ Texture Features â”€â”€â”€\\n"
            glcm = features["glcm"]
            text += f"Contrast:    {glcm.get('contrast', 0):.4f}\\n"
            text += f"Energy:      {glcm.get('energy', 0):.4f}\\n"
            text += f"Homogeneity: {glcm.get('homogeneity', 0):.4f}\\n"
            text += f"Correlation: {glcm.get('correlation', 0):.4f}\\n"
        
        self.results_text.setText(text)'''

if old3 in content:
    content = content.replace(old3, new3)
    changes.append("âœ… Rich results display with emojis and all VLM fields")

# Fix 4: Add Summary box
old4 = '''        layout.addWidget(results_group)
        
        layout.addStretch()
        
        return panel'''

new4 = '''        layout.addWidget(results_group)
        
        # Summary panel (NEW)
        summary_group = QGroupBox("ğŸ“‹ Summary")
        summary_layout = QVBoxLayout(summary_group)
        
        self.summary_text = QTextEdit()
        self.summary_text.setReadOnly(True)
        self.summary_text.setMaximumHeight(150)
        self.summary_text.setPlaceholderText("Plain-English summary will appear here...")
        self.summary_text.setStyleSheet(
            "QTextEdit { background-color: #1a1a2e; border: 2px solid #4a4a6a; border-radius: 8px; padding: 10px; font-size: 11px; line-height: 1.4; }"
        )
        summary_layout.addWidget(self.summary_text)
        
        layout.addWidget(summary_group)
        
        layout.addStretch()
        
        return panel'''

if old4 in content:
    content = content.replace(old4, new4)
    changes.append("âœ… Added Summary box for non-technical users")

# Fix 5: Call summary generation
old5 = '        self.results_text.setText(text)\n        self.status_bar.showMessage("Analysis complete!")'
new5 = '        self.results_text.setText(text)\n        \n        # Generate plain-English summary\n        self.generate_summary(result, classification)\n        \n        self.status_bar.showMessage("Analysis complete!")'

if old5 in content:
    content = content.replace(old5, new5)
    changes.append("âœ… Added summary generation call")

# Fix 6: Add generate_summary method
old6 = '''                    self.legend_items[layer_num].setVisible(False)

    def analysis_error(self, error_msg):'''

new6 = '''                    self.legend_items[layer_num].setVisible(False)
    
    def generate_summary(self, result: dict, classification: dict):
        """Generate plain-English summary for non-technical users."""
        mode = self.mode if hasattr(self, 'mode') else self.get_current_mode()
        
        layer_name = classification.get('layer_name', classification.get('full_name', 'Unknown'))
        confidence = classification.get('confidence', 0)
        material = classification.get('material', '')
        
        # Build summary based on mode
        if mode == "vlm":
            summary = "ğŸ¤– **VLM Analysis Summary**\\n\\n"
            summary += f"The AI vision model analyzed your image and identified it as:\\n\\n"
            summary += f"ğŸ“Œ **{layer_name}**\\n\\n"
            
            # Confidence explanation
            if confidence >= 0.8:
                summary += f"âœ… The model is very confident ({confidence:.0%}) about this identification.\\n\\n"
            elif confidence >= 0.6:
                summary += f"âš ï¸  The model is moderately confident ({confidence:.0%}) about this identification.\\n\\n"
            else:
                summary += f"â“ The model has low confidence ({confidence:.0%}) - consider using another analysis mode.\\n\\n"
            
            # Material explanation
            if material and material != 'N/A':
                summary += f"ğŸ§± **Material:** {material}\\n\\n"
            
            # Simple explanation
            if "Aggregate" in layer_name:
                summary += "ğŸ’¡ **What this means:** This layer shows loose stones/gravel used for drainage and stability.\\n"
            elif "Sub-base" in layer_name:
                summary += "ğŸ’¡ **What this means:** This is a foundational layer that distributes loads evenly.\\n"
            elif "Base Course" in layer_name:
                summary += "ğŸ’¡ **What this means:** This is the main structural layer that bears traffic loads.\\n"
            elif "Asphalt" in layer_name or "Surface" in layer_name:
                summary += "ğŸ’¡ **What this means:** This is the top wearing course that vehicles travel on.\\n"
            elif "Soil" in layer_name or "Subgrade" in layer_name:
                summary += "ğŸ’¡ **What this means:** This is the natural soil foundation beneath all road layers.\\n"
        
        elif mode == "deep_learning":
            summary = "ğŸ§  **Deep Learning Analysis Summary**\\n\\n"
            summary += f"The neural network (DeepLabv3+) segmented your image.\\n\\n"
            summary += f"ğŸ“Œ **Primary Layer:** {layer_name}\\n\\n"
            summary += f"ğŸ”¬ This mode uses advanced AI trained on thousands of road images to identify layers.\\n"
            summary += f"âœ… Great for complex images with mixed materials.\\n"
        
        elif mode == "classical":
            summary = "ğŸ“ **Classical Analysis Summary**\\n\\n"
            summary += f"Traditional image processing techniques were used:\\n\\n"
            summary += f"ğŸ“Œ **Identified Layer:** {layer_name}\\n"
            summary += f"ğŸ“Š **Confidence:** {confidence:.0%}\\n\\n"
            
            if material:
                summary += f"ğŸ§± **Material Type:** {material}\\n\\n"
            
            summary += "ğŸ”¬ **How it worked:**\\n"
            summary += "â€¢ Extracted texture features (GLCM, LBP)\\n"
            summary += "â€¢ Applied K-means clustering segmentation\\n"
            summary += "â€¢ Used heuristic rules to classify layers\\n\\n"
            summary += "âœ… This mode is fast and works well for clear, distinct textures.\\n"
        
        elif mode == "hybrid":
            summary = "ğŸ”€ **Hybrid Analysis Summary**\\n\\n"
            summary += f"Combined classical and AI methods for best accuracy:\\n\\n"
            summary += f"ğŸ“Œ **Final Result:** {layer_name}\\n"
            summary += f"ğŸ“Š **Combined Confidence:** {confidence:.0%}\\n\\n"
            summary += "ğŸ¤ **Best of both worlds:**\\n"
            summary += "â€¢ Classical: Fast texture analysis\\n"
            summary += "â€¢ VLM: Smart AI understanding\\n"
            summary += "âœ… Most accurate for challenging images.\\n"
        
        else:
            summary = f"ğŸ“Š Analysis complete: {layer_name} ({confidence:.0%} confidence)"
        
        self.summary_text.setText(summary)

    def analysis_error(self, error_msg):'''

if old6 in content:
    content = content.replace(old6, new6)
    changes.append("âœ… Implemented generate_summary method with mode-specific explanations")

# Fix 7: Mode tracking
old7 = '''        mode = self.get_current_mode()
        params = self.get_parameters()
        
        self.worker = AnalysisWorker(self.image.copy(), mode, params)'''
new7 = '''        mode = self.get_current_mode()
        self.mode = mode  # Store mode for summary generation
        params = self.get_parameters()
        
        self.worker = AnalysisWorker(self.image.copy(), mode, params)'''

if old7 in content:
    content = content.replace(old7, new7)
    changes.append("âœ… Added mode tracking for summary generation")

# Fix 8: VLM method field
old8 = '''                    vlm_result = analyzer.analyze_road_layer(str(temp_path))
                    result["classification"] = vlm_result

                    # Create smart VLM visualization'''

new8 = '''                    vlm_result = analyzer.analyze_road_layer(str(temp_path))
                    
                    # Ensure method field is populated
                    if 'method' not in vlm_result or vlm_result.get('method') == 'N/A':
                        vlm_result['method'] = 'VLM Analysis (GLM-4.6V)'
                    
                    result["classification"] = vlm_result

                    # Create smart VLM visualization'''

if old8 in content:
    content = content.replace(old8, new8)
    changes.append("âœ… VLM method field populated")

# Save changes
if changes:
    backup_file = project_root / "gui" / "main_window.py.backup"
    with open(backup_file, 'w', encoding='utf-8') as f:
        # Write original content to backup
        with open(gui_file, 'r', encoding='utf-8') as orig:
            f.write(orig.read())
    
    with open(gui_file, 'w', encoding='utf-8') as f:
        f.write(content)
    
    print("ğŸ‰ GUI IMPROVEMENTS APPLIED!")
    print("="*50)
    for change in changes:
        print(change)
    print("="*50)
    print(f"âœ… Backup: {backup_file}")
    print(f"âœ… Updated: {gui_file}")
    print("\nğŸš€ Ready to test!")
else:
    print("âš ï¸  No changes needed - file may already be updated")
